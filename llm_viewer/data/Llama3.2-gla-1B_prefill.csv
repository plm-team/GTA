

=== ../Llama3.2-gla-1B nvidia_H100 w_bit=16 a_bit=16 kv_bit=16 batchsize=1 seqlen=2048 tp_size=1 ===
layer_name,OPs,Access,arithmetic_intensity,performance,bound,load_weight,load_act,store_act,load_kv_cache,store_kv_cache,inference_time
q_proj,1.7G,7.4MB,227.6,699T,memory,819KB,5.2MB,1.3MB,0.00B,0.00B,2.4us
k_proj,336M,5.7MB,59.2,182T,memory,164KB,5.2MB,0.00B,0.00B,262KB,1.8us
v_proj,671M,6.1MB,110.1,338T,memory,328KB,5.2MB,0.00B,0.00B,524KB,2.0us
out_proj,6.7G,13.8MB,487.6,990T,compute,3.3MB,5.2MB,5.2MB,0.00B,0.00B,6.8us
v2o_proj,671M,4.0MB,167.9,516T,memory,328KB,2.6MB,1.0MB,0.00B,0.00B,1.3us
nl_proj,6.7G,13.8MB,487.6,990T,compute,3.3MB,5.2MB,5.2MB,0.00B,0.00B,6.8us
gate_proj,18.8G,29.1MB,645.8,990T,compute,9.2MB,5.2MB,14.7MB,0.00B,0.00B,19.0us
up_proj,18.8G,29.1MB,645.8,990T,compute,9.2MB,5.2MB,14.7MB,0.00B,0.00B,19.0us
down_proj,18.8G,29.1MB,645.8,990T,compute,9.2MB,14.7MB,5.2MB,0.00B,0.00B,19.0us
qk_matmul,2.7G,42.5MB,63.2,194T,memory,0.00B,262KB,41.9MB,262KB,0.00B,13.8us
sv_matmul,5.4G,45.1MB,119.1,366T,memory,0.00B,41.9MB,2.6MB,524KB,0.00B,14.7us
softmax,105M,83.9MB,1.2,3.8T,memory,0.00B,41.9MB,41.9MB,0.00B,0.00B,27.3us
attn_norm,18.4M,10.5MB,1.8,5.4T,memory,0.00B,5.2MB,5.2MB,0.00B,0.00B,3.4us
mlp_norm,18.4M,10.5MB,1.8,5.4T,memory,0.00B,5.2MB,5.2MB,0.00B,0.00B,3.4us
output_add,2.6M,10.5MB,0.25,768G,memory,0.00B,5.2MB,5.2MB,0.00B,0.00B,3.4us
gate_act,5.2M,15.7MB,0.33,1.0T,memory,0.00B,10.5MB,5.2MB,0.00B,0.00B,5.1us
attn_add,2.6M,10.5MB,0.25,768G,memory,0.00B,5.2MB,5.2MB,0.00B,0.00B,3.4us
mlp_add,2.6M,10.5MB,0.25,768G,memory,0.00B,5.2MB,5.2MB,0.00B,0.00B,3.4us
mlp_act,14.7M,34.6MB,0.42,1.3T,memory,0.00B,29.4MB,5.2MB,0.00B,0.00B,11.3us
lm_head,164M,329MB,0.50,1.5T,memory,328MB,2.6KB,257KB,0.00B,0.00B,107.0us


=== ../Llama3.2-gla-1B nvidia_H100 w_bit=16 a_bit=16 kv_bit=16 batchsize=1 seqlen=1024 tp_size=1 ===
layer_name,OPs,Access,arithmetic_intensity,performance,bound,load_weight,load_act,store_act,load_kv_cache,store_kv_cache,inference_time
q_proj,839M,4.1MB,204.8,629T,memory,819KB,2.6MB,655KB,0.00B,0.00B,1.3us
k_proj,168M,2.9MB,57.5,177T,memory,164KB,2.6MB,0.00B,0.00B,131KB,949.3ns
v_proj,336M,3.2MB,104.5,321T,memory,328KB,2.6MB,0.00B,0.00B,262KB,1.0us
out_proj,3.4G,8.5MB,393.8,990T,compute,3.3MB,2.6MB,2.6MB,0.00B,0.00B,3.4us
v2o_proj,336M,2.2MB,155.2,477T,memory,328KB,1.3MB,524KB,0.00B,0.00B,704.0ns
nl_proj,3.4G,8.5MB,393.8,990T,compute,3.3MB,2.6MB,2.6MB,0.00B,0.00B,3.4us
gate_proj,9.4G,19.1MB,491.0,990T,compute,9.2MB,2.6MB,7.3MB,0.00B,0.00B,9.5us
up_proj,9.4G,19.1MB,491.0,990T,compute,9.2MB,2.6MB,7.3MB,0.00B,0.00B,9.5us
down_proj,9.4G,19.1MB,491.0,990T,compute,9.2MB,7.3MB,2.6MB,0.00B,0.00B,9.5us
qk_matmul,671M,10.7MB,62.4,192T,memory,0.00B,131KB,10.5MB,131KB,0.00B,3.5us
sv_matmul,1.3G,12.1MB,111.3,342T,memory,0.00B,10.5MB,1.3MB,262KB,0.00B,3.9us
softmax,26.2M,21.0MB,1.2,3.8T,memory,0.00B,10.5MB,10.5MB,0.00B,0.00B,6.8us
attn_norm,9.2M,5.2MB,1.8,5.4T,memory,0.00B,2.6MB,2.6MB,0.00B,0.00B,1.7us
mlp_norm,9.2M,5.2MB,1.8,5.4T,memory,0.00B,2.6MB,2.6MB,0.00B,0.00B,1.7us
output_add,1.3M,5.2MB,0.25,768G,memory,0.00B,2.6MB,2.6MB,0.00B,0.00B,1.7us
gate_act,2.6M,7.9MB,0.33,1.0T,memory,0.00B,5.2MB,2.6MB,0.00B,0.00B,2.6us
attn_add,1.3M,5.2MB,0.25,768G,memory,0.00B,2.6MB,2.6MB,0.00B,0.00B,1.7us
mlp_add,1.3M,5.2MB,0.25,768G,memory,0.00B,2.6MB,2.6MB,0.00B,0.00B,1.7us
mlp_act,7.3M,17.3MB,0.42,1.3T,memory,0.00B,14.7MB,2.6MB,0.00B,0.00B,5.6us
lm_head,164M,329MB,0.50,1.5T,memory,328MB,2.6KB,257KB,0.00B,0.00B,107.0us


=== ../Llama3.2-gla-1B nvidia_H100 w_bit=16 a_bit=16 kv_bit=16 batchsize=1 seqlen=512 tp_size=1 ===
layer_name,OPs,Access,arithmetic_intensity,performance,bound,load_weight,load_act,store_act,load_kv_cache,store_kv_cache,inference_time
q_proj,419M,2.5MB,170.7,524T,memory,819KB,1.3MB,328KB,0.00B,0.00B,800.0ns
k_proj,83.9M,1.5MB,54.5,167T,memory,164KB,1.3MB,0.00B,0.00B,65.5KB,501.3ns
v_proj,168M,1.8MB,94.8,291T,memory,328KB,1.3MB,0.00B,0.00B,131KB,576.0ns
out_proj,1.7G,5.9MB,284.4,874T,memory,3.3MB,1.3MB,1.3MB,0.00B,0.00B,1.9us
v2o_proj,168M,1.2MB,134.7,414T,memory,328KB,655KB,262KB,0.00B,0.00B,405.3ns
nl_proj,1.7G,5.9MB,284.4,874T,memory,3.3MB,1.3MB,1.3MB,0.00B,0.00B,1.9us
gate_proj,4.7G,14.2MB,331.9,990T,compute,9.2MB,1.3MB,3.7MB,0.00B,0.00B,4.7us
up_proj,4.7G,14.2MB,331.9,990T,compute,9.2MB,1.3MB,3.7MB,0.00B,0.00B,4.7us
down_proj,4.7G,14.2MB,331.9,990T,compute,9.2MB,3.7MB,1.3MB,0.00B,0.00B,4.7us
qk_matmul,168M,2.8MB,61.0,187T,memory,0.00B,65.5KB,2.6MB,65.5KB,0.00B,896.0ns
sv_matmul,336M,3.4MB,98.5,302T,memory,0.00B,2.6MB,655KB,131KB,0.00B,1.1us
softmax,6.6M,5.2MB,1.2,3.8T,memory,0.00B,2.6MB,2.6MB,0.00B,0.00B,1.7us
attn_norm,4.6M,2.6MB,1.8,5.4T,memory,0.00B,1.3MB,1.3MB,0.00B,0.00B,853.3ns
mlp_norm,4.6M,2.6MB,1.8,5.4T,memory,0.00B,1.3MB,1.3MB,0.00B,0.00B,853.3ns
output_add,655K,2.6MB,0.25,768G,memory,0.00B,1.3MB,1.3MB,0.00B,0.00B,853.3ns
gate_act,1.3M,3.9MB,0.33,1.0T,memory,0.00B,2.6MB,1.3MB,0.00B,0.00B,1.3us
attn_add,655K,2.6MB,0.25,768G,memory,0.00B,1.3MB,1.3MB,0.00B,0.00B,853.3ns
mlp_add,655K,2.6MB,0.25,768G,memory,0.00B,1.3MB,1.3MB,0.00B,0.00B,853.3ns
mlp_act,3.7M,8.7MB,0.42,1.3T,memory,0.00B,7.3MB,1.3MB,0.00B,0.00B,2.8us
lm_head,164M,329MB,0.50,1.5T,memory,328MB,2.6KB,257KB,0.00B,0.00B,107.0us


=== ../Llama3.2-gla-1B nvidia_H100 w_bit=16 a_bit=16 kv_bit=16 batchsize=1 seqlen=128 tp_size=1 ===
layer_name,OPs,Access,arithmetic_intensity,performance,bound,load_weight,load_act,store_act,load_kv_cache,store_kv_cache,inference_time
q_proj,105M,1.2MB,85.3,262T,memory,819KB,328KB,81.9KB,0.00B,0.00B,400.0ns
k_proj,21.0M,508KB,41.3,127T,memory,164KB,328KB,0.00B,0.00B,16.4KB,165.3ns
v_proj,41.9M,688KB,61.0,187T,memory,328KB,328KB,0.00B,0.00B,32.8KB,224.0ns
out_proj,419M,3.9MB,106.7,328T,memory,3.3MB,328KB,328KB,0.00B,0.00B,1.3us
v2o_proj,41.9M,557KB,75.3,231T,memory,328KB,164KB,65.5KB,0.00B,0.00B,181.3ns
nl_proj,419M,3.9MB,106.7,328T,memory,3.3MB,328KB,328KB,0.00B,0.00B,1.3us
gate_proj,1.2G,10.4MB,112.7,346T,memory,9.2MB,328KB,918KB,0.00B,0.00B,3.4us
up_proj,1.2G,10.4MB,112.7,346T,memory,9.2MB,328KB,918KB,0.00B,0.00B,3.4us
down_proj,1.2G,10.4MB,112.7,346T,memory,9.2MB,918KB,328KB,0.00B,0.00B,3.4us
qk_matmul,10.5M,197KB,53.3,164T,memory,0.00B,16.4KB,164KB,16.4KB,0.00B,64.0ns
sv_matmul,21.0M,360KB,58.2,179T,memory,0.00B,164KB,164KB,32.8KB,0.00B,117.3ns
softmax,410K,328KB,1.2,3.8T,memory,0.00B,164KB,164KB,0.00B,0.00B,106.7ns
attn_norm,1.1M,655KB,1.8,5.4T,memory,0.00B,328KB,328KB,0.00B,0.00B,213.3ns
mlp_norm,1.1M,655KB,1.8,5.4T,memory,0.00B,328KB,328KB,0.00B,0.00B,213.3ns
output_add,164K,655KB,0.25,768G,memory,0.00B,328KB,328KB,0.00B,0.00B,213.3ns
gate_act,328K,983KB,0.33,1.0T,memory,0.00B,655KB,328KB,0.00B,0.00B,320.0ns
attn_add,164K,655KB,0.25,768G,memory,0.00B,328KB,328KB,0.00B,0.00B,213.3ns
mlp_add,164K,655KB,0.25,768G,memory,0.00B,328KB,328KB,0.00B,0.00B,213.3ns
mlp_act,918K,2.2MB,0.42,1.3T,memory,0.00B,1.8MB,328KB,0.00B,0.00B,704.0ns
lm_head,164M,329MB,0.50,1.5T,memory,328MB,2.6KB,257KB,0.00B,0.00B,107.0us


=== ../Llama3.2-gla-1B nvidia_H100 w_bit=16 a_bit=16 kv_bit=16 batchsize=32 seqlen=2048 tp_size=1 ===
layer_name,OPs,Access,arithmetic_intensity,performance,bound,load_weight,load_act,store_act,load_kv_cache,store_kv_cache,inference_time
q_proj,53.7G,211MB,255.0,783T,memory,819KB,168MB,41.9MB,0.00B,0.00B,68.5us
k_proj,10.7G,176MB,60.9,187T,memory,164KB,168MB,0.00B,0.00B,8.4MB,57.4us
v_proj,21.5G,185MB,116.2,357T,memory,328KB,168MB,0.00B,0.00B,16.8MB,60.2us
out_proj,215G,339MB,633.8,990T,compute,3.3MB,168MB,168MB,0.00B,0.00B,217.0us
v2o_proj,21.5G,118MB,182.3,560T,memory,328KB,83.9MB,33.6MB,0.00B,0.00B,38.3us
nl_proj,215G,339MB,633.8,990T,compute,3.3MB,168MB,168MB,0.00B,0.00B,217.0us
gate_proj,601G,647MB,929.8,990T,compute,9.2MB,168MB,470MB,0.00B,0.00B,607.7us
up_proj,601G,647MB,929.8,990T,compute,9.2MB,168MB,470MB,0.00B,0.00B,607.7us
down_proj,601G,647MB,929.8,990T,compute,9.2MB,470MB,168MB,0.00B,0.00B,607.7us
qk_matmul,85.9G,1.4GB,63.2,194T,memory,0.00B,8.4MB,1.3GB,8.4MB,0.00B,442.4us
sv_matmul,172G,1.4GB,119.1,366T,memory,0.00B,1.3GB,83.9MB,16.8MB,0.00B,469.7us
softmax,3.4G,2.7GB,1.2,3.8T,memory,0.00B,1.3GB,1.3GB,0.00B,0.00B,873.8us
attn_norm,587M,336MB,1.8,5.4T,memory,0.00B,168MB,168MB,0.00B,0.00B,109.2us
mlp_norm,587M,336MB,1.8,5.4T,memory,0.00B,168MB,168MB,0.00B,0.00B,109.2us
output_add,83.9M,336MB,0.25,768G,memory,0.00B,168MB,168MB,0.00B,0.00B,109.2us
gate_act,168M,503MB,0.33,1.0T,memory,0.00B,336MB,168MB,0.00B,0.00B,163.8us
attn_add,83.9M,336MB,0.25,768G,memory,0.00B,168MB,168MB,0.00B,0.00B,109.2us
mlp_add,83.9M,336MB,0.25,768G,memory,0.00B,168MB,168MB,0.00B,0.00B,109.2us
mlp_act,470M,1.1GB,0.42,1.3T,memory,0.00B,940MB,168MB,0.00B,0.00B,360.4us
lm_head,5.3G,329MB,16.0,49.1T,memory,328MB,2.6KB,257KB,0.00B,0.00B,107.0us


=== ../Llama3.2-gla-1B nvidia_H100 w_bit=16 a_bit=16 kv_bit=16 batchsize=32 seqlen=1024 tp_size=1 ===
layer_name,OPs,Access,arithmetic_intensity,performance,bound,load_weight,load_act,store_act,load_kv_cache,store_kv_cache,inference_time
q_proj,26.8G,106MB,254.0,780T,memory,819KB,83.9MB,21.0MB,0.00B,0.00B,34.4us
k_proj,5.4G,88.2MB,60.8,187T,memory,164KB,83.9MB,0.00B,0.00B,4.2MB,28.7us
v_proj,10.7G,92.6MB,116.0,356T,memory,328KB,83.9MB,0.00B,0.00B,8.4MB,30.1us
out_proj,107G,171MB,627.7,990T,compute,3.3MB,83.9MB,83.9MB,0.00B,0.00B,108.5us
v2o_proj,10.7G,59.0MB,181.8,559T,memory,328KB,41.9MB,16.8MB,0.00B,0.00B,19.2us
nl_proj,107G,171MB,627.7,990T,compute,3.3MB,83.9MB,83.9MB,0.00B,0.00B,108.5us
gate_proj,301G,328MB,916.8,990T,compute,9.2MB,83.9MB,235MB,0.00B,0.00B,303.8us
up_proj,301G,328MB,916.8,990T,compute,9.2MB,83.9MB,235MB,0.00B,0.00B,303.8us
down_proj,301G,328MB,916.8,990T,compute,9.2MB,235MB,83.9MB,0.00B,0.00B,303.8us
qk_matmul,21.5G,344MB,62.4,192T,memory,0.00B,4.2MB,336MB,4.2MB,0.00B,112.0us
sv_matmul,42.9G,386MB,111.3,342T,memory,0.00B,336MB,41.9MB,8.4MB,0.00B,125.6us
softmax,839M,671MB,1.2,3.8T,memory,0.00B,336MB,336MB,0.00B,0.00B,218.5us
attn_norm,294M,168MB,1.8,5.4T,memory,0.00B,83.9MB,83.9MB,0.00B,0.00B,54.6us
mlp_norm,294M,168MB,1.8,5.4T,memory,0.00B,83.9MB,83.9MB,0.00B,0.00B,54.6us
output_add,41.9M,168MB,0.25,768G,memory,0.00B,83.9MB,83.9MB,0.00B,0.00B,54.6us
gate_act,83.9M,252MB,0.33,1.0T,memory,0.00B,168MB,83.9MB,0.00B,0.00B,81.9us
attn_add,41.9M,168MB,0.25,768G,memory,0.00B,83.9MB,83.9MB,0.00B,0.00B,54.6us
mlp_add,41.9M,168MB,0.25,768G,memory,0.00B,83.9MB,83.9MB,0.00B,0.00B,54.6us
mlp_act,235M,554MB,0.42,1.3T,memory,0.00B,470MB,83.9MB,0.00B,0.00B,180.2us
lm_head,5.3G,329MB,16.0,49.1T,memory,328MB,2.6KB,257KB,0.00B,0.00B,107.0us


=== ../Llama3.2-gla-1B nvidia_H100 w_bit=16 a_bit=16 kv_bit=16 batchsize=32 seqlen=512 tp_size=1 ===
layer_name,OPs,Access,arithmetic_intensity,performance,bound,load_weight,load_act,store_act,load_kv_cache,store_kv_cache,inference_time
q_proj,13.4G,53.2MB,252.1,774T,memory,819KB,41.9MB,10.5MB,0.00B,0.00B,17.3us
k_proj,2.7G,44.2MB,60.7,187T,memory,164KB,41.9MB,0.00B,0.00B,2.1MB,14.4us
v_proj,5.4G,46.5MB,115.5,355T,memory,328KB,41.9MB,0.00B,0.00B,4.2MB,15.1us
out_proj,53.7G,87.2MB,615.9,990T,compute,3.3MB,41.9MB,41.9MB,0.00B,0.00B,54.3us
v2o_proj,5.4G,29.7MB,180.8,556T,memory,328KB,21.0MB,8.4MB,0.00B,0.00B,9.7us
nl_proj,53.7G,87.2MB,615.9,990T,compute,3.3MB,41.9MB,41.9MB,0.00B,0.00B,54.3us
gate_proj,150G,169MB,891.8,990T,compute,9.2MB,41.9MB,117MB,0.00B,0.00B,151.9us
up_proj,150G,169MB,891.8,990T,compute,9.2MB,41.9MB,117MB,0.00B,0.00B,151.9us
down_proj,150G,169MB,891.8,990T,compute,9.2MB,117MB,41.9MB,0.00B,0.00B,151.9us
qk_matmul,5.4G,88.1MB,61.0,187T,memory,0.00B,2.1MB,83.9MB,2.1MB,0.00B,28.7us
sv_matmul,10.7G,109MB,98.5,302T,memory,0.00B,83.9MB,21.0MB,4.2MB,0.00B,35.5us
softmax,210M,168MB,1.2,3.8T,memory,0.00B,83.9MB,83.9MB,0.00B,0.00B,54.6us
attn_norm,147M,83.9MB,1.8,5.4T,memory,0.00B,41.9MB,41.9MB,0.00B,0.00B,27.3us
mlp_norm,147M,83.9MB,1.8,5.4T,memory,0.00B,41.9MB,41.9MB,0.00B,0.00B,27.3us
output_add,21.0M,83.9MB,0.25,768G,memory,0.00B,41.9MB,41.9MB,0.00B,0.00B,27.3us
gate_act,41.9M,126MB,0.33,1.0T,memory,0.00B,83.9MB,41.9MB,0.00B,0.00B,41.0us
attn_add,21.0M,83.9MB,0.25,768G,memory,0.00B,41.9MB,41.9MB,0.00B,0.00B,27.3us
mlp_add,21.0M,83.9MB,0.25,768G,memory,0.00B,41.9MB,41.9MB,0.00B,0.00B,27.3us
mlp_act,117M,277MB,0.42,1.3T,memory,0.00B,235MB,41.9MB,0.00B,0.00B,90.1us
lm_head,5.3G,329MB,16.0,49.1T,memory,328MB,2.6KB,257KB,0.00B,0.00B,107.0us


=== ../Llama3.2-gla-1B nvidia_H100 w_bit=16 a_bit=16 kv_bit=16 batchsize=32 seqlen=128 tp_size=1 ===
layer_name,OPs,Access,arithmetic_intensity,performance,bound,load_weight,load_act,store_act,load_kv_cache,store_kv_cache,inference_time
q_proj,3.4G,13.9MB,240.9,740T,memory,819KB,10.5MB,2.6MB,0.00B,0.00B,4.5us
k_proj,671M,11.2MB,60.1,185T,memory,164KB,10.5MB,0.00B,0.00B,524KB,3.6us
v_proj,1.3G,11.9MB,113.1,348T,memory,328KB,10.5MB,0.00B,0.00B,1.0MB,3.9us
out_proj,13.4G,24.2MB,553.5,990T,compute,3.3MB,10.5MB,10.5MB,0.00B,0.00B,13.6us
v2o_proj,1.3G,7.7MB,175.0,538T,memory,328KB,5.2MB,2.1MB,0.00B,0.00B,2.5us
nl_proj,13.4G,24.2MB,553.5,990T,compute,3.3MB,10.5MB,10.5MB,0.00B,0.00B,13.6us
gate_proj,37.6G,49.0MB,766.6,990T,compute,9.2MB,10.5MB,29.4MB,0.00B,0.00B,38.0us
up_proj,37.6G,49.0MB,766.6,990T,compute,9.2MB,10.5MB,29.4MB,0.00B,0.00B,38.0us
down_proj,37.6G,49.0MB,766.6,990T,compute,9.2MB,29.4MB,10.5MB,0.00B,0.00B,38.0us
qk_matmul,336M,6.3MB,53.3,164T,memory,0.00B,524KB,5.2MB,524KB,0.00B,2.0us
sv_matmul,671M,11.5MB,58.2,179T,memory,0.00B,5.2MB,5.2MB,1.0MB,0.00B,3.8us
softmax,13.1M,10.5MB,1.2,3.8T,memory,0.00B,5.2MB,5.2MB,0.00B,0.00B,3.4us
attn_norm,36.7M,21.0MB,1.8,5.4T,memory,0.00B,10.5MB,10.5MB,0.00B,0.00B,6.8us
mlp_norm,36.7M,21.0MB,1.8,5.4T,memory,0.00B,10.5MB,10.5MB,0.00B,0.00B,6.8us
output_add,5.2M,21.0MB,0.25,768G,memory,0.00B,10.5MB,10.5MB,0.00B,0.00B,6.8us
gate_act,10.5M,31.5MB,0.33,1.0T,memory,0.00B,21.0MB,10.5MB,0.00B,0.00B,10.2us
attn_add,5.2M,21.0MB,0.25,768G,memory,0.00B,10.5MB,10.5MB,0.00B,0.00B,6.8us
mlp_add,5.2M,21.0MB,0.25,768G,memory,0.00B,10.5MB,10.5MB,0.00B,0.00B,6.8us
mlp_act,29.4M,69.2MB,0.42,1.3T,memory,0.00B,58.7MB,10.5MB,0.00B,0.00B,22.5us
lm_head,5.3G,329MB,16.0,49.1T,memory,328MB,2.6KB,257KB,0.00B,0.00B,107.0us
